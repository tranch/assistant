// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: nlp.proto

package pb

import (
	context "context"
	fmt "fmt"
	proto "github.com/gogo/protobuf/proto"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type WordsReply struct {
	Text                 []string `protobuf:"bytes,1,rep,name=text,proto3" json:"text,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WordsReply) Reset()         { *m = WordsReply{} }
func (m *WordsReply) String() string { return proto.CompactTextString(m) }
func (*WordsReply) ProtoMessage()    {}
func (*WordsReply) Descriptor() ([]byte, []int) {
	return fileDescriptor_6ebd3cd177a18baf, []int{0}
}
func (m *WordsReply) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WordsReply.Unmarshal(m, b)
}
func (m *WordsReply) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WordsReply.Marshal(b, m, deterministic)
}
func (m *WordsReply) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WordsReply.Merge(m, src)
}
func (m *WordsReply) XXX_Size() int {
	return xxx_messageInfo_WordsReply.Size(m)
}
func (m *WordsReply) XXX_DiscardUnknown() {
	xxx_messageInfo_WordsReply.DiscardUnknown(m)
}

var xxx_messageInfo_WordsReply proto.InternalMessageInfo

func (m *WordsReply) GetText() []string {
	if m != nil {
		return m.Text
	}
	return nil
}

func init() {
	proto.RegisterType((*WordsReply)(nil), "pb.WordsReply")
}

func init() { proto.RegisterFile("nlp.proto", fileDescriptor_6ebd3cd177a18baf) }

var fileDescriptor_6ebd3cd177a18baf = []byte{
	// 173 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0xe2, 0xcc, 0xcb, 0x29, 0xd0,
	0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x17, 0x62, 0x2a, 0x48, 0x92, 0xe2, 0x4a, 0x4a, 0x2c, 0x4e, 0x85,
	0xf0, 0x95, 0x14, 0xb8, 0xb8, 0xc2, 0xf3, 0x8b, 0x52, 0x8a, 0x83, 0x52, 0x0b, 0x72, 0x2a, 0x85,
	0x84, 0xb8, 0x58, 0x4a, 0x52, 0x2b, 0x4a, 0x24, 0x18, 0x15, 0x98, 0x35, 0x38, 0x83, 0xc0, 0x6c,
	0xa3, 0xa9, 0x8c, 0x5c, 0xcc, 0x7e, 0x3e, 0x01, 0x42, 0xda, 0x5c, 0x6c, 0x01, 0x99, 0x79, 0x95,
	0x99, 0x79, 0x42, 0xfc, 0x7a, 0x05, 0x49, 0x7a, 0x21, 0xa9, 0x15, 0x25, 0x41, 0xa9, 0x85, 0xa5,
	0xa9, 0xc5, 0x25, 0x52, 0x7c, 0x20, 0x01, 0x84, 0x31, 0x4a, 0x0c, 0x42, 0x86, 0x5c, 0x3c, 0xc1,
	0xa9, 0xe9, 0xb9, 0xa9, 0x79, 0x25, 0x89, 0x25, 0x99, 0xf9, 0x44, 0x69, 0xd1, 0xe3, 0xe2, 0x72,
	0xce, 0x49, 0x2c, 0x2e, 0xce, 0x4c, 0xcb, 0x4c, 0x2d, 0xc2, 0xd4, 0xc0, 0x8b, 0x10, 0x00, 0xab,
	0x77, 0xe2, 0x88, 0x62, 0x4b, 0x2c, 0xc8, 0xd4, 0x2f, 0x48, 0x4a, 0x62, 0x03, 0x7b, 0xc5, 0x18,
	0x10, 0x00, 0x00, 0xff, 0xff, 0xe2, 0x7d, 0x65, 0x0f, 0xe7, 0x00, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// NLPClient is the client API for NLP service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type NLPClient interface {
	Pinyin(ctx context.Context, in *TextRequest, opts ...grpc.CallOption) (*WordsReply, error)
	Segmentation(ctx context.Context, in *TextRequest, opts ...grpc.CallOption) (*WordsReply, error)
	Classifier(ctx context.Context, in *TextRequest, opts ...grpc.CallOption) (*TextReply, error)
}

type nLPClient struct {
	cc *grpc.ClientConn
}

func NewNLPClient(cc *grpc.ClientConn) NLPClient {
	return &nLPClient{cc}
}

func (c *nLPClient) Pinyin(ctx context.Context, in *TextRequest, opts ...grpc.CallOption) (*WordsReply, error) {
	out := new(WordsReply)
	err := c.cc.Invoke(ctx, "/pb.NLP/Pinyin", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *nLPClient) Segmentation(ctx context.Context, in *TextRequest, opts ...grpc.CallOption) (*WordsReply, error) {
	out := new(WordsReply)
	err := c.cc.Invoke(ctx, "/pb.NLP/Segmentation", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *nLPClient) Classifier(ctx context.Context, in *TextRequest, opts ...grpc.CallOption) (*TextReply, error) {
	out := new(TextReply)
	err := c.cc.Invoke(ctx, "/pb.NLP/Classifier", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// NLPServer is the server API for NLP service.
type NLPServer interface {
	Pinyin(context.Context, *TextRequest) (*WordsReply, error)
	Segmentation(context.Context, *TextRequest) (*WordsReply, error)
	Classifier(context.Context, *TextRequest) (*TextReply, error)
}

// UnimplementedNLPServer can be embedded to have forward compatible implementations.
type UnimplementedNLPServer struct {
}

func (*UnimplementedNLPServer) Pinyin(ctx context.Context, req *TextRequest) (*WordsReply, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Pinyin not implemented")
}
func (*UnimplementedNLPServer) Segmentation(ctx context.Context, req *TextRequest) (*WordsReply, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Segmentation not implemented")
}
func (*UnimplementedNLPServer) Classifier(ctx context.Context, req *TextRequest) (*TextReply, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Classifier not implemented")
}

func RegisterNLPServer(s *grpc.Server, srv NLPServer) {
	s.RegisterService(&_NLP_serviceDesc, srv)
}

func _NLP_Pinyin_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(TextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NLPServer).Pinyin(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.NLP/Pinyin",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NLPServer).Pinyin(ctx, req.(*TextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _NLP_Segmentation_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(TextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NLPServer).Segmentation(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.NLP/Segmentation",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NLPServer).Segmentation(ctx, req.(*TextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _NLP_Classifier_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(TextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(NLPServer).Classifier(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/pb.NLP/Classifier",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(NLPServer).Classifier(ctx, req.(*TextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _NLP_serviceDesc = grpc.ServiceDesc{
	ServiceName: "pb.NLP",
	HandlerType: (*NLPServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Pinyin",
			Handler:    _NLP_Pinyin_Handler,
		},
		{
			MethodName: "Segmentation",
			Handler:    _NLP_Segmentation_Handler,
		},
		{
			MethodName: "Classifier",
			Handler:    _NLP_Classifier_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "nlp.proto",
}
